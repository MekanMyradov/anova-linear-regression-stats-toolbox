{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa50d723",
   "metadata": {},
   "source": [
    "# ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82a2de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44779f99",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972b612",
   "metadata": {},
   "source": [
    "##### One-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "feadc8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova1_partition_tss(X):\n",
    "    \"\"\"\n",
    "    Partition the total sum of squares (ss_total) into between-group sum of squares (ss_b) and within-group sum of squares (ss_w).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        A 2D array where each row represents a group and each column represents an observation.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ss_total : float\n",
    "        Total sum of squares.\n",
    "    ss_w : float\n",
    "        Within-group sum of squares.\n",
    "    ss_b : float\n",
    "        Between-group sum of squares.\n",
    "    \"\"\"\n",
    "\n",
    "    # Flatten the input array and calculate the total mean\n",
    "    all_data = np.concatenate(X)\n",
    "    grand_mean = np.mean(all_data)  # X_bar\n",
    "\n",
    "    # Calculate the total sum of squares\n",
    "    ss_total = np.sum((all_data - grand_mean) ** 2)\n",
    "\n",
    "    # Calculate the means and sizes of each group\n",
    "    group_means = [np.mean(group) for group in X]\n",
    "    group_sizes = [len(group) for group in X]\n",
    "\n",
    "    # Calculate the between-group sum of squares\n",
    "    ss_b = np.sum([size * (group_mean - grand_mean) ** 2 for group_mean, size in zip(group_means, group_sizes)])\n",
    "\n",
    "    # Calculate the within-group sum of squares\n",
    "    ss_w = np.sum([np.sum((group - group_mean) ** 2) for group, group_mean in zip(X, group_means)])\n",
    "\n",
    "    return ss_total, ss_w, ss_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af0fa8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova1_test_equality(X, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Tests the equality of means in one-way ANOVA.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        A 2D array where each row represents a group and each column represents an observation.\n",
    "    alpha : float, optional\n",
    "        Significance level for the test. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None, prints the ANOVA table, critical value, p-value, and whether to reject the null hypothesis.\n",
    "    \"\"\"\n",
    "    # Number of groups\n",
    "    I = len(X)\n",
    "\n",
    "    # Total number of observations\n",
    "    N = sum(len(group) for group in X)\n",
    "\n",
    "    # Degrees of freedom\n",
    "    df_b = I - 1  # Between-group degrees of freedom\n",
    "    df_w = N - I  # Within-group degrees of freedom\n",
    "    df_total = N - 1  # Total degrees of freedom\n",
    "\n",
    "    # Partition the total sum of squares\n",
    "    ss_total, ss_w, ss_b = anova1_partition_tss(X)\n",
    "\n",
    "    # Calculate the mean squares\n",
    "    ms_b = ss_b / df_b  # Mean square between\n",
    "    ms_w = ss_w / df_w  # Mean square within\n",
    "\n",
    "    # Calculate the F-statistic\n",
    "    F = ms_b / ms_w\n",
    "\n",
    "    # Calculate the critical value from the F-distribution\n",
    "    f_critical = stats.f.ppf(1 - alpha, df_b, df_w)\n",
    "\n",
    "    # Calculate the p-value\n",
    "    p_value = 1 - stats.f.cdf(F, df_b, df_w)\n",
    "\n",
    "    # Print the ANOVA table\n",
    "    print(\"\\nANOVA Table\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Source':<15} {'df':<10} {'SS':<15} {'MS':<15} {'F':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Between':<15} {df_b:<10} {ss_b:<15.4f} {ms_b:<15.4f} {F:<15.4f}\")\n",
    "    print(f\"{'Within':<15} {df_w:<10} {ss_w:<15.4f} {ms_w:<15.4f}\")\n",
    "    print(f\"{'Total':<15} {df_total:<10} {ss_total:<15.4f}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Critical value (f_{alpha}_{df_b}_{df_w}): {f_critical:.4f}\")\n",
    "    print(f\"p-value: {p_value:.8f}\")\n",
    "\n",
    "    # Decision\n",
    "    decision = \"Reject H0\" if F > f_critical else \"Fail to reject H0\"\n",
    "    interpretation = (\"There is signifant evidence to suggest that at least one group mean is different.\"\n",
    "                      if decision == \"Reject H0\"\n",
    "                      else \"There is not enough evidence to suggest that group means are different.\")\n",
    "\n",
    "    print(f\"Decision ({alpha=}): {decision}\")\n",
    "    print(f\"Interpretation: {interpretation}\")\n",
    "\n",
    "    return {\n",
    "        'F': F,\n",
    "        'p_value': p_value,\n",
    "        'f_critical': f_critical,\n",
    "        'SS_between': ss_b,\n",
    "        'SS_within': ss_w,\n",
    "        'SS_total': ss_total,\n",
    "        'df_between': df_b,\n",
    "        'df_within': df_w,\n",
    "        'df_total': df_total,\n",
    "        'MS_between': ms_b,\n",
    "        'MS_within': ms_w,\n",
    "        'decision': decision,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "210f39b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova1_is_contrast(c):\n",
    "    \"\"\"\n",
    "    Determines if a linear combination defined by coefficients is a contrast.\n",
    "    A contrast is a linear combination where the sum of coefficients is zero.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    c: list or numpy array\n",
    "        Coefficients defining the linear combination\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    bool\n",
    "        True if the linear combination is a contrast, False otherwise\n",
    "    \"\"\"\n",
    "    return abs(sum(c)) < 1e-10  # Using a small tolerance for floating-point arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2a91c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova1_is_orthogonal(group_sizes, coef1, coef2):\n",
    "    \"\"\"\n",
    "    Determines if two contrasts are orthogonal.\n",
    "    Contrasts are orthogonal if the sum of (c1_i * c2_i / n_i) is zero.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    group_sizes: list or np array\n",
    "        Sizes of each group\n",
    "    coef1: list or np array\n",
    "        Coefficients of the first linear combination\n",
    "    coef2: list or np array\n",
    "        Coefficients of the second linear combination\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    bool\n",
    "        True if the contrasts are orthogonal, False otherwise\n",
    "    \"\"\"\n",
    "    # Check if both are contrasts\n",
    "    if not anova1_is_contrast(c=coef1):\n",
    "        print(\"Warning: The first linear combination is not a contrast\")\n",
    "        return False\n",
    "    \n",
    "    if not anova1_is_contrast(c=coef2):\n",
    "        print(\"Warning: The second linear combination is not a contrast\")\n",
    "        return False\n",
    "    \n",
    "    # Check orthogonality\n",
    "    orthogonality_sum = sum(c1 * c2 / n for c1, c2, n in zip(coef1, coef2, group_sizes))\n",
    "    return abs(orthogonality_sum) < 1e-10 # Using a small tolerance for floating-point arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "321de76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonferroni_correction(alpha, m):\n",
    "    \"\"\"\n",
    "    Determines the significance level with Bonferroni correction.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    alpha: float\n",
    "        Family-wise error rate (FWER)\n",
    "    m: int\n",
    "        Number of tests\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Individual test significance level\n",
    "    \"\"\"\n",
    "    return alpha / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88337d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sidak_correction(alpha, m):\n",
    "    \"\"\"\n",
    "    Determines the significance level with Sidak correction.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    alpha: float\n",
    "        Family-wise error rate (FWER)\n",
    "    m: int\n",
    "        Number of tests\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Individual test significance level\n",
    "    \"\"\"\n",
    "    return 1 - (1 - alpha) ** (1 / m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fed8b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all are pairwise comparisons (of the form [0,0,1,-1,0,0])\n",
    "def is_pairwise(c):\n",
    "    return sum(1 for x in c if abs(x) > 1e-10) == 2 and any(abs(abs(x) - 1) < 1e-10 for x in c) and sum(c) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bee9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova1_ci_linear_combs(X, alpha, C, method=\"best\"):\n",
    "    \"\"\"\n",
    "    Computes simultaneous confidence intervals for linear combinations of group means.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X: list of lists or numpy arrays\n",
    "        Each inner list/array contains observations for one group\n",
    "    alpha: float\n",
    "        Significance level\n",
    "    C: np array\n",
    "        An m x I matrix where each row defines a linear combination of the group means\n",
    "    method: str\n",
    "        Method for confidence intervals: \"Scheffe\", \"Tukey\", \"Bonferroni\", \"Sidak\" or \"best\"\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list of tuples\n",
    "        Confidence intervals for each linear combination\n",
    "    method:\n",
    "        The actual method used to calculate CI\n",
    "    \"\"\"\n",
    "    # Number of groups and total observations\n",
    "    I = len(X)\n",
    "    group_sizes = [len(group) for group in X]\n",
    "    N = sum(group_sizes)    # sum of all n_i\n",
    "    m = C.shape[0]  # Number of linear combinations\n",
    "\n",
    "    # Compute group means\n",
    "    group_means = np.array([np.mean(group) for group in X])\n",
    "\n",
    "    # Calculate within-group mean square (MSE)\n",
    "    _, ss_w, _ = anova1_partition_tss(X=X)\n",
    "    df_w = N - I\n",
    "    mse = ss_w / df_w\n",
    "\n",
    "    # Determine if all combinations are contrasts\n",
    "    all_contrasts = all(anova1_is_contrast(c=C[i]) for i in range(m))\n",
    "\n",
    "    all_pairwise = all(is_pairwise(c) for c in C)\n",
    "\n",
    "    # Check orthogonality of contrasts (check all contrasts pairwise) \n",
    "    are_orthogonal = True\n",
    "    if all_contrasts and m > 1:\n",
    "        for i in range(m):\n",
    "            for j in range(i+1, m):\n",
    "                if not anova1_is_orthogonal(group_sizes=group_sizes, coef1=C[i], coef2=C[j]):\n",
    "                    # Found a pair which are not orthogonal\n",
    "                    are_orthogonal = False\n",
    "                    break\n",
    "            if not are_orthogonal:\n",
    "                break\n",
    "    \n",
    "    # Calculate the estimate of each linear combination, sum of c_i * X_i bar\n",
    "    estimates = [np.sum(c * group_means) for c in C]\n",
    "\n",
    "    # Select the appropriate method if \"best\" is chosen\n",
    "    if method == \"best\":\n",
    "        if all_contrasts:\n",
    "            if are_orthogonal:\n",
    "                # Case: 4\n",
    "                if all_pairwise:\n",
    "                    # All orthogonal and pairwise: Thm 2.11 (Tukey CI for pairwise differences) vs Sidak\n",
    "                    tukey_q = stats.studentized_range.ppf(1 - alpha, I, df_w)\n",
    "                    sidak_alpha = sidak_correction(alpha=alpha, m=m)\n",
    "\n",
    "                    # Calculate t factor\n",
    "                    sidak_t = stats.t.ppf(1 - sidak_alpha/2, df_w)\n",
    "\n",
    "                    method = \"Tukey\" if tukey_q / np.sqrt(2) < sidak_t else \"Sidak\"\n",
    "                # Case: 1\n",
    "                else:\n",
    "                    # Orthogonal contrasts: Thm 2.7 (Scheffe's thm for contrasts) vs Sidak\n",
    "                    sidak_alpha = sidak_correction(alpha=alpha, m=m)\n",
    "\n",
    "                    # Calculate t and M factors\n",
    "                    sidak_t = stats.t.ppf(1 - sidak_alpha/2, df_w)\n",
    "                    scheffe_m = np.sqrt((I - 1) * stats.f.ppf(1 - alpha, I - 1, df_w))\n",
    "\n",
    "                    method = \"Sidak\" if sidak_t < scheffe_m else \"Scheffe\"\n",
    "            # Case: 3\n",
    "            elif all_pairwise:\n",
    "                # All pairwise: Thm 2.11 (Tukey CI for pairwise differences) vs Bonferroni\n",
    "                tukey_q = stats.studentized_range.ppf(1 - alpha, I, df_w)\n",
    "                bonferroni_alpha = bonferroni_correction(alpha=alpha, m=m)\n",
    "\n",
    "                # Calculate t factor\n",
    "                bonferroni_t = stats.t.ppf(1 - bonferroni_alpha/2, df_w)\n",
    "\n",
    "                method = \"Tukey\" if tukey_q / np.sqrt(2) < bonferroni_t else \"Bonferroni\"\n",
    "            # Case: 2\n",
    "            else:\n",
    "                # Non-orthogonal contrasts: Thm 2.7 (Scheffe's thm for contrasts) vs Bonferroni\n",
    "                scheffe_m = np.sqrt((I - 1) * stats.f.ppf(1 - alpha, I - 1, df_w))\n",
    "                bonferroni_alpha = bonferroni_correction(alpha=alpha, m=m)\n",
    "\n",
    "                bonferroni_t = stats.t.ppf(1 - bonferroni_alpha/2, df_w)\n",
    "\n",
    "                method = \"Bonferroni\" if bonferroni_t < scheffe_m else \"Scheffe\"\n",
    "        # Case: 5\n",
    "        else:\n",
    "            # Not all contrasts: Thm 2.6 (Scheffe's thm for linear combinations) vs Bonferroni\n",
    "            scheffe_m = np.sqrt(I * stats.f.ppf(1 - alpha, I, df_w))\n",
    "            bonferroni_alpha = bonferroni_correction(alpha=alpha, m=m)\n",
    "\n",
    "            bonferroni_t = stats.t.ppf(1 - bonferroni_alpha/2, df_w)\n",
    "            \n",
    "            method = \"Bonferroni\" if bonferroni_t < scheffe_m else \"Scheffe\"\n",
    "\n",
    "    # Calculate confidence intervals based on the selected method\n",
    "    intervals = []\n",
    "    \n",
    "    if method == \"Scheffe\":\n",
    "        if all_contrasts:\n",
    "            # Apply Thm 2.7 (Scheffe's thm for contrasts)\n",
    "            scheffe_m = np.sqrt((I - 1) * stats.f.ppf(1 - alpha, I - 1, df_w))\n",
    "        else:\n",
    "            # Apply Thm 2.6 (Scheffe's thm for linear combinations)\n",
    "            scheffe_m = np.sqrt(I * stats.f.ppf(1 - alpha, I, df_w))\n",
    "\n",
    "        for i, c in enumerate(C):\n",
    "            half_width = scheffe_m * np.sqrt((ss_w / df_w) * sum(c**2 / group_sizes))\n",
    "            intervals.append((estimates[i] - half_width, estimates[i] + half_width))\n",
    "    \n",
    "    elif method == \"Tukey\":\n",
    "        if not all_pairwise:\n",
    "            print(\"Warning: Tukey's method is only valid for pairwise comparisons.\")\n",
    "            return None\n",
    "        \n",
    "        tukey_q = stats.studentized_range.ppf(1 - alpha, I, df_w)\n",
    "        \n",
    "        for i, c in enumerate(C):\n",
    "            # Find 2 non-zero components\n",
    "            idx1, idx2 = [j for j, val in enumerate(c) if abs(val) > 1e-10]\n",
    "            half_width = (tukey_q / np.sqrt(2)) * np.sqrt((ss_w / df_w) * (1 / group_sizes[idx1] + 1 / group_sizes[idx2]))\n",
    "            intervals.append((estimates[i] - half_width, estimates[i] + half_width))\n",
    "    \n",
    "    elif method == \"Bonferroni\":\n",
    "        bonferroni_alpha = bonferroni_correction(alpha=alpha, m=m)\n",
    "        bonferroni_t = stats.t.ppf(1 - bonferroni_alpha/2, df_w)\n",
    "\n",
    "        for i, c in enumerate(C):\n",
    "            half_width = bonferroni_t * np.sqrt((ss_w/df_w) * sum(c**2 / group_sizes))\n",
    "            intervals.append((estimates[i] - half_width, estimates[i] + half_width))\n",
    "    \n",
    "    elif method == \"Sidak\":\n",
    "        if not all_contrasts:\n",
    "            print(\"Warning: Sidak's method is only valid for contrasts in this implementation\")\n",
    "            return None\n",
    "        \n",
    "        sidak_alpha = sidak_correction(alpha=alpha, m=m)\n",
    "        sidak_t = stats.t.ppf(1 - sidak_alpha/2, df_w)\n",
    "\n",
    "        for i, c in enumerate(C):\n",
    "            half_width = sidak_t * np.sqrt((ss_w / df_w) * sum(c**2 / group_sizes))\n",
    "            intervals.append((estimates[i] - half_width, estimates[i] + half_width))\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Method '{method}' not recognized.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Using method: {method}\")\n",
    "    return intervals, method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e2c3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova1_test_linear_combs(X, alpha, C, d, method=\"best\"):\n",
    "    \"\"\"\n",
    "    Performs simultaneous hypothesis tests for linear combinations of group means.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X: list of lists or numpy arrays\n",
    "        Each inner list/array contains observations for one group\n",
    "    alpha: float\n",
    "        Family-Wise Error Rate (FWER)\n",
    "    C: np.array\n",
    "        An m x I matrix where each row defines a linear combination of the group means\n",
    "    d: np array\n",
    "        An m x 1 vector of hypothesized values for each linear combination\n",
    "    method: str\n",
    "        Method for hypothesis testing: \"Scheffe\", \"Tukey\", \"Bonferroni\", \"Sidak\" or \"best\"\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        A dictionary containing:\n",
    "        - 'reject': boolean array indicating which hypotheses to reject\n",
    "        - 'p_values': p-values for each hypothesis test\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the CI and the method used\n",
    "    confidence_intervals, actual_method = anova1_ci_linear_combs(X=X, alpha=alpha, C=C, method=method)\n",
    "\n",
    "    # Number of groups and total observations\n",
    "    I = len(X)\n",
    "    group_sizes = [len(group) for group in X]\n",
    "    N = sum(group_sizes)\n",
    "    m = C.shape[0]  # Number of linear combinations\n",
    "\n",
    "    # Compute group means\n",
    "    group_means = np.array([np.mean(group) for group in X])\n",
    "\n",
    "    # Calculate within-group mean square (MSE)\n",
    "    _, ss_w, _ = anova1_partition_tss(X=X)\n",
    "    df_w = N - I\n",
    "    mse = ss_w / df_w\n",
    "\n",
    "    # Calculate the estimate of each linear combination\n",
    "    estimates = [np.sum(c * group_means) for c in C]\n",
    "\n",
    "    # Determine if all combinations are contrasts (to differentiate M factors in Thm 2.6 & 2.7)\n",
    "    all_contrasts = all(anova1_is_contrast(c=C[i]) for i in range(m))\n",
    "\n",
    "    # Determine rejection decisions based on CI\n",
    "    reject = np.zeros(m, dtype=bool)\n",
    "    p_values = np.zeros(m)\n",
    "\n",
    "    # For each linear combination\n",
    "    for i in range(m):\n",
    "        # Reject H0, if d[i] is outside the CI\n",
    "        reject[i] = not (confidence_intervals[i][0] <= d[i] <= confidence_intervals[i][1])\n",
    "\n",
    "        # Calculate the test statistic\n",
    "        diff = estimates[i] - d[i]\n",
    "        t_stat = abs(diff) / np.sqrt(mse * sum(C[i]**2 / group_sizes))\n",
    "\n",
    "        # Calculate p-value based on the actual method used\n",
    "        if actual_method == \"Scheffe\":\n",
    "            # Thm 2.7 (Scheffe's thm for contrasts)\n",
    "            if all_contrasts:\n",
    "                # For contrasts, compute F with I-1 numerator df\n",
    "                # f_stat = abs_t_stat**2 * (I - 1)    # may be problematic\n",
    "                f_stat = (diff ** 2) / ((I - 1) * mse * sum(C[i]**2 / group_sizes))\n",
    "                p_values[i] = 1 - stats.f.cdf(f_stat, I-1, df_w)\n",
    "            \n",
    "            # Thm 2.6 (Scheffe's thm for linear combs)\n",
    "            else:\n",
    "                # For general linear combs, compute F with I numerator df\n",
    "                # f_stat = abs_t_stat**2 * I  # may be problematic\n",
    "                f_stat = (diff ** 2) / (I * mse * sum(C[i]**2 / group_sizes))\n",
    "                p_values[i] = 1 - stats.f.cdf(f_stat, I, df_w)\n",
    "        \n",
    "        elif actual_method == \"Tukey\":\n",
    "            # Convert t-statistic to studentized range statistic q\n",
    "            q_stat = t_stat * np.sqrt(2)\n",
    "            p_values[i] = 1 - stats.studentized_range.cdf(q_stat, I, df_w)\n",
    "        \n",
    "        elif actual_method == \"Bonferroni\":\n",
    "            # Calculate p-value using t-distr and apply Bonferroni correction\n",
    "            # No need to adjust alpha, adjust p_value itself\n",
    "            p_value_uncorrected = 2 * (1 - stats.t.cdf(t_stat, df_w))   # t-distr is symmetric\n",
    "            p_values[i] = min(p_value_uncorrected * m, 1.0)\n",
    "        \n",
    "        elif actual_method == \"Sidak\":\n",
    "            # Calculate p-value using t-distribution and apply Sidak correction\n",
    "            p_value_uncorrected = 2 * (1 - stats.t.cdf(t_stat, df_w))\n",
    "            p_values[i] = 1 - (1 - p_value_uncorrected)**(1/m) if p_value_uncorrected < 1 else 1.0\n",
    "\n",
    "    # Make sure reject decisions are consistent with p-values\n",
    "    # This serves as a double-check - both should give the same result\n",
    "    for i in range(m):\n",
    "        if p_values[i] < alpha:\n",
    "            if not reject[i]:\n",
    "                print(f\"Warning: Inconsistency detected for hypothesis {i+1}. \"\n",
    "                        f\"p-value = {p_values[i]:.6f} < {alpha}, but CI contains d[{i}] = {d[i]}\")\n",
    "\n",
    "    return {\n",
    "        'reject': reject,\n",
    "        'p_values': p_values\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4866028",
   "metadata": {},
   "source": [
    "##### Two-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69c0a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova2_partition_tss(X):\n",
    "    \"\"\"\n",
    "    Partition the total sum of squares (ss_total) in a two-way ANOVA layout.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        A 3D array where X[i,j,k] is the k-th observation in the (i,j)-th cell\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ss_total : float\n",
    "        Total sum of squares.\n",
    "    ss_a : float\n",
    "        Sum of squares for factor A.\n",
    "    ss_b : float\n",
    "        Sum of squares for factor B.\n",
    "    ss_ab : float\n",
    "        Sum of squares for the interaction between factors A and B.\n",
    "    ss_e : float\n",
    "        Sum of squares for error.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get dimensions\n",
    "    I, J, K = X.shape\n",
    "\n",
    "    # Calculate cell means, row means, column means, and grand mean\n",
    "    cell_means = np.mean(X, axis=2)\n",
    "    row_means = np.mean(cell_means, axis=1)\n",
    "    col_means = np.mean(cell_means, axis=0)\n",
    "    grand_mean = np.mean(X)\n",
    "\n",
    "    # Flatten the data to compute total sum of squares\n",
    "    all_data = X.flatten()\n",
    "    ss_total = np.sum((all_data - grand_mean) ** 2)\n",
    "\n",
    "    # Calculate the sum of squares for factor A\n",
    "    ss_a = J * K * np.sum((row_means - grand_mean) ** 2)\n",
    "\n",
    "    # Calculate the sum of squares for factor B\n",
    "    ss_b = I * K * np.sum((col_means - grand_mean) ** 2)\n",
    "\n",
    "    # Calculate the sum of squares for the interaction between factors A and B\n",
    "    ss_ab = K * np.sum((cell_means - np.outer(row_means, np.ones(J)) - \n",
    "                        np.outer(np.ones(I), col_means) + grand_mean) ** 2)\n",
    "    \n",
    "    # Calculate the sum of squares for error\n",
    "    ss_e = 0.0\n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            ss_e += np.sum((X[i, j, :] - cell_means[i, j]) ** 2)\n",
    "\n",
    "    return ss_total, ss_a, ss_b, ss_ab, ss_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "402d1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova2_mle(X):\n",
    "    \"\"\"\n",
    "    Computes the maximum likelihood estimates (MLE) for parameters in a two-way ANOVA.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        A 3D array where X[i,j,k] is the k-th observation in the (i,j)-th cell\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    mu : float\n",
    "        Estimate of the grand mean.\n",
    "    a : np.array\n",
    "        Estimates of the row effects (factor A).\n",
    "    b : np.array\n",
    "        Estimates of the column effects (factor B).\n",
    "    delta : np.array\n",
    "        Estimates of the interaction effects (factor A x factor B).\n",
    "    \"\"\"\n",
    "\n",
    "    # Get dimensions\n",
    "    I, J, K = X.shape\n",
    "\n",
    "    # Calculate cell means, row means, column means, and grand mean\n",
    "    cell_means = np.mean(X, axis=2)\n",
    "    row_means = np.mean(cell_means, axis=1)\n",
    "    col_means = np.mean(cell_means, axis=0)\n",
    "    grand_mean = np.mean(X)\n",
    "\n",
    "    # Calculate main effects\n",
    "    a = row_means - grand_mean\n",
    "    b = col_means - grand_mean\n",
    "\n",
    "    # Calculate interaction effects\n",
    "    delta = np.zeros((I, J))\n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            delta[i, j] = cell_means[i, j] - row_means[i] - col_means[j] + grand_mean\n",
    "\n",
    "    return grand_mean, a, b, delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "788e9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova2_test_equality(X, alpha=0.05, test_type=\"A\"):\n",
    "    \"\"\"\n",
    "    Perform one of the basic three tests for two-way ANOVA.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        A 3D array where X[i,j,k] is the k-th observation in the (i,j)-th cell\n",
    "    alpha : float, optional\n",
    "        Significance level for the test. Default is 0.05.\n",
    "    test_type : str, optional\n",
    "        Type of test to perform. Options are \"A\", \"B\", or \"AB\" for main effects A, B, or interaction AB. Default is \"A\".\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Test outcome with relevant statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get dimensions\n",
    "    I, J, K = X.shape\n",
    "\n",
    "    # Partition the total sum of squares\n",
    "    ss_total, ss_a, ss_b, ss_ab, ss_e = anova2_partition_tss(X)\n",
    "\n",
    "    # Calculate degrees of freedom\n",
    "    df_a = I - 1  # Degrees of freedom for factor A\n",
    "    df_b = J - 1  # Degrees of freedom for factor B\n",
    "    df_ab = (I - 1) * (J - 1)  # Degrees of freedom for interaction\n",
    "    df_e = I * J * (K - 1)  # Degrees of freedom for error\n",
    "    df_total = I * J * K - 1  # Total degrees of freedom\n",
    "\n",
    "    # Calculate mean squares\n",
    "    ms_a = ss_a / df_a  # Mean square for factor A\n",
    "    ms_b = ss_b / df_b  # Mean square for factor B\n",
    "    ms_ab = ss_ab / df_ab  # Mean square for interaction\n",
    "    ms_e = ss_e / df_e  # Mean square for error\n",
    "\n",
    "    # Calculate F-statistics\n",
    "    F_a = ms_a / ms_e  # F-statistic for factor A\n",
    "    F_b = ms_b / ms_e  # F-statistic for factor B\n",
    "    F_ab = ms_ab / ms_e  # F-statistic for interaction\n",
    "\n",
    "    # Calculate critical values from the F-distribution\n",
    "    f_critical_a = stats.f.ppf(1 - alpha, df_a, df_e)\n",
    "    f_critical_b = stats.f.ppf(1 - alpha, df_b, df_e)\n",
    "    f_critical_ab = stats.f.ppf(1 - alpha, df_ab, df_e)\n",
    "\n",
    "    # Calculate p-values\n",
    "    p_value_a = 1 - stats.f.cdf(F_a, df_a, df_e)\n",
    "    p_value_b = 1 - stats.f.cdf(F_b, df_b, df_e)\n",
    "    p_value_ab = 1 - stats.f.cdf(F_ab, df_ab, df_e)\n",
    "\n",
    "    # Print the ANOVA table\n",
    "    print(\"\\nTwo-Way ANOVA Table:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Source':<15} {'df':<10} {'SS':<15} {'MS':<15} {'F':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    if test_type == \"A\" or test_type == \"all\":\n",
    "        print(f\"{'Factor A':<15} {df_a:<10} {ss_a:<15.4f} {ms_a:<15.4f} {F_a:<15.4f}\")\n",
    "    if test_type == \"B\" or test_type == \"all\":\n",
    "        print(f\"{'Factor B':<15} {df_b:<10} {ss_b:<15.4f} {ms_b:<15.4f} {F_b:<15.4f}\")\n",
    "    if test_type == \"AB\" or test_type == \"all\":\n",
    "        print(f\"{'Interaction':<15} {df_ab:<10} {ss_ab:<15.4f} {ms_ab:<15.4f} {F_ab:<15.4f}\")\n",
    "\n",
    "    print(f\"{'Error':<15} {df_e:<10} {ss_e:<15.4f} {ms_e:<15.4f}\")\n",
    "    print(f\"{'Total':<15} {df_total:<10} {ss_total:<15.4f}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Decision and interpretation\n",
    "    if test_type == \"A\":\n",
    "        f_stat = F_a\n",
    "        f_critical = f_critical_a\n",
    "        p_value = p_value_a\n",
    "        h0_description = \"a_1 = a_2 = ... = a_I\"\n",
    "    elif test_type == \"B\":\n",
    "        f_stat = F_b\n",
    "        f_critical = f_critical_b\n",
    "        p_value = p_value_b\n",
    "        h0_description = \"b_1 = b_2 = ... = b_J\"\n",
    "    elif test_type == \"AB\":\n",
    "        f_stat = F_ab\n",
    "        f_critical = f_critical_ab\n",
    "        p_value = p_value_ab\n",
    "        h0_description = \"all delta_ij = 0\"\n",
    "\n",
    "    decision = \"Reject H0\" if f_stat > f_critical else \"Fail to reject H0\"\n",
    "\n",
    "    print(f\"\\nTesting H0: {h0_description}\")\n",
    "    print(f\"Decision ({alpha=}): {decision}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    print(f\"Critical value (f): {f_critical:.4f}\")\n",
    "\n",
    "    if test_type == \"A\":\n",
    "        return {\n",
    "            'F': F_a,\n",
    "            'p_value': p_value_a,\n",
    "            'f_critical': f_critical_a,\n",
    "            'SS': ss_a,\n",
    "            'MS': ms_a,\n",
    "            'df': df_a,\n",
    "            'decision': decision\n",
    "        }\n",
    "    elif test_type == \"B\":\n",
    "        return {\n",
    "            'F': F_b,\n",
    "            'p_value': p_value_b,\n",
    "            'f_critical': f_critical_b,\n",
    "            'SS': ss_b,\n",
    "            'MS': ms_b,\n",
    "            'df': df_b,\n",
    "            'decision': decision\n",
    "        }\n",
    "    elif test_type == \"AB\":\n",
    "        return {\n",
    "            'F': F_ab,\n",
    "            'p_value': p_value_ab,\n",
    "            'f_critical': f_critical_ab,\n",
    "            'SS': ss_ab,\n",
    "            'MS': ms_ab,\n",
    "            'df': df_ab,\n",
    "            'decision': decision\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d2b006",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af408609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_lr_least_squares(X, y):\n",
    "    \"\"\"\n",
    "    Finds the least squares estimates for a multiple linear regression model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        n x (k+1) design matrix where the first column is all ones\n",
    "    y : array_like\n",
    "        n x 1 response vector\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    beta_hat : np.array\n",
    "        (k+1) x 1 vector of maximum likelihood estimates for the regression coefficients\n",
    "    sigma2_hat : float\n",
    "        Maximum likelihood estimate of the error variance\n",
    "    sigma2_hat_unbiased : float\n",
    "        Unbiased estimate of the error variance\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of observations and predictors\n",
    "    n, k_plus_1 = X.shape\n",
    "\n",
    "    # Check if X has full column rank\n",
    "    if np.linalg.matrix_rank(X) < k_plus_1:\n",
    "        raise ValueError(\"Design matrix X does not have full column rank.\")\n",
    "    \n",
    "    # Calculate the least squares estimates\n",
    "    beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "    # Calculate the residuals\n",
    "    residuals = y - X @ beta_hat\n",
    "\n",
    "    # Calculate MLE of error variance\n",
    "    sigma2_hat = np.sum(residuals**2) / n\n",
    "\n",
    "    # Calculate unbiased estimate of error variance\n",
    "    sigma2_hat_unbiased = np.sum(residuals**2) / (n - k_plus_1)\n",
    "\n",
    "    return beta_hat, sigma2_hat, sigma2_hat_unbiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1289a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_lr_partition_tss(X, y):\n",
    "    \"\"\"\n",
    "    Partitions the total sum of squares into regression and residual components in a multiple linear regression model.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        n x (k+1) design matrix where the first column is all ones\n",
    "    y : array_like\n",
    "        n x 1 response vector\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ss_total : float\n",
    "        Total sum of squares.\n",
    "    ss_reg : float\n",
    "        Regression sum of squares.\n",
    "    ss_res : float\n",
    "        Residual sum of squares.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the least squares estimates\n",
    "    beta_hat, _, _ = mult_lr_least_squares(X, y)\n",
    "\n",
    "    # Calculate the fitted values\n",
    "    y_hat = X @ beta_hat\n",
    "\n",
    "    # Calculate mean of y\n",
    "    y_mean = np.mean(y)\n",
    "\n",
    "    # Calculate sums of squares\n",
    "    ss_total = np.sum((y - y_mean) ** 2)\n",
    "    ss_reg = np.sum((y_hat - y_mean) ** 2)\n",
    "    ss_res = np.sum((y - y_hat) ** 2)\n",
    "\n",
    "    return ss_total, ss_reg, ss_res\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d14811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_norm_lr_simul_ci(X, y, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Computes simultaneous confidence intervals for the regression coefficients in a multiple linear regression model.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        n x (k+1) design matrix where the first column is all ones\n",
    "    y : array_like\n",
    "        n x 1 response vector\n",
    "    alpha : float, optional\n",
    "        Significance level for the confidence intervals. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list of tuples\n",
    "        100(1-alpha)% confidence intervals (lower, upper) for each regression coefficient.\n",
    "    method : str\n",
    "        The method used for the confidence intervals: \"Bonferroni\" or \"Scheffe\".\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of observations and predictors\n",
    "    n, k_plus_1 = X.shape\n",
    "\n",
    "    # Calculate the least squares estimates\n",
    "    beta_hat, _, sigma2_hat_unbiased = mult_lr_least_squares(X, y)\n",
    "\n",
    "    # Square root of the unbiased estimate of the error variance\n",
    "    s_e = np.sqrt(sigma2_hat_unbiased)\n",
    "\n",
    "    cov_matrix = np.linalg.inv(X.T @ X)\n",
    "\n",
    "    # Calculate the critical value from the t-distribution\n",
    "    bonf_alpha = bonferroni_correction(alpha=alpha, m=k_plus_1)\n",
    "    t_critical = stats.t.ppf(1 - bonf_alpha / 2, n - k_plus_1)\n",
    "\n",
    "    # Calculate Scheffe's M factor\n",
    "    scheffe_m = np.sqrt(k_plus_1 * stats.f.ppf(1 - alpha, k_plus_1, n - k_plus_1))\n",
    "\n",
    "    # Use the minimum of the two methods\n",
    "    if t_critical <= scheffe_m:\n",
    "        method = \"Bonferroni\"\n",
    "        half_widths = t_critical * s_e * np.sqrt(np.diag(cov_matrix))\n",
    "    else:\n",
    "        method = \"Scheffe\"\n",
    "        half_widths = scheffe_m * s_e * np.sqrt(np.diag(cov_matrix))\n",
    "\n",
    "    # Calculate confidence intervals\n",
    "    ci = []\n",
    "    for i in range(k_plus_1):\n",
    "        lower_bound = beta_hat[i] - half_widths[i]\n",
    "        upper_bound = beta_hat[i] + half_widths[i]\n",
    "        ci.append((lower_bound, upper_bound))\n",
    "\n",
    "    return ci, method\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0444685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_norm_lr_cr(X, y, C, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Computes 100(1-alpha)% confidence region for a linear combination of regression coefficients in a multiple linear regression model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        n x (k+1) design matrix where the first column is all ones\n",
    "    y : array_like\n",
    "        n x 1 response vector\n",
    "    C: array_like\n",
    "        r x (k+1) matrix of coefficients for the linear combinations with rank r\n",
    "    alpha : float, optional\n",
    "        Significance level for the confidence region. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Parameters specifying the confidence region:\n",
    "        - 'center': center of the confidence region\n",
    "        - 'shape_matrix': shape matrix of the confidence region\n",
    "        - 'radius_squared': square of radius of the confidence region\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of observations and predictors\n",
    "    n, k_plus_1 = X.shape\n",
    "\n",
    "    r = C.shape[0]  # Number of linear combinations\n",
    "\n",
    "    XtX_inv = np.linalg.inv(X.T @ X)\n",
    "\n",
    "    # Shape matrix: C @ (X^T X)^-1 @ C^T\n",
    "    shape_matrix = C @ XtX_inv @ C.T\n",
    "\n",
    "    # Calculate the least squares estimates\n",
    "    beta_hat, _, sigma2_hat_unbiased = mult_lr_least_squares(X, y)\n",
    "\n",
    "    # Calculate center: C*beta_hat\n",
    "    C_beta_hat = C @ beta_hat\n",
    "\n",
    "    # Calculate the critical value from the F-distribution\n",
    "    f_critical = stats.f.ppf(1 - alpha, r, n - k_plus_1)\n",
    "    \n",
    "    # Calculate the radius\n",
    "    radius_squared = r * sigma2_hat_unbiased * f_critical\n",
    "\n",
    "    return {\n",
    "        'center': C_beta_hat,\n",
    "        'shape_matrix': shape_matrix,\n",
    "        'radius_squared': radius_squared,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bcba8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_norm_lr_is_in_cr(X, y, C, c0, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Checks if a vector c0 is inside the confidence region for C*beta.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        n x (k+1) design matrix where the first column is all ones\n",
    "    y : array_like\n",
    "        n x 1 response vector\n",
    "    C: array_like\n",
    "        r x (k+1) matrix of coefficients for the linear combinations with rank r\n",
    "    c0: array_like\n",
    "        r x 1 vector to check if it is in the confidence region\n",
    "    alpha : float, optional\n",
    "        Significance level for the confidence region. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    bool\n",
    "        True if c0 is inside the confidence region, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of observations and predictors\n",
    "    n, k_plus_1 = X.shape\n",
    "\n",
    "    r = C.shape[0]  # Number of linear combinations\n",
    "\n",
    "    # Calculate the least squares estimates\n",
    "    beta_hat, _, sigma2_hat_unbiased = mult_lr_least_squares(X, y)\n",
    "\n",
    "    # Get the confidence region parameters\n",
    "    cr_params = mult_norm_lr_cr(X=X, y=y, C=C, alpha=alpha)\n",
    "\n",
    "    center = cr_params['center']\n",
    "    shape_matrix = cr_params['shape_matrix']\n",
    "    radius_squared = cr_params['radius_squared']\n",
    "\n",
    "    diff = center - c0\n",
    "\n",
    "    left_side = diff.T @ np.linalg.inv(shape_matrix) @ diff\n",
    "    \n",
    "    return left_side <= radius_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ffcc67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_norm_lr_test_general(X, y, C, c0, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Tests the null hypothesis H0: C*beta = c0 vs H1: C*beta != c0 at significance level alpha.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        n x (k+1) design matrix where the first column is all ones\n",
    "    y : array_like\n",
    "        n x 1 response vector\n",
    "    C: array_like\n",
    "        r x (k+1) matrix of coefficients for the linear combinations with rank r\n",
    "    c0: array_like\n",
    "        r x 1 vector of hypothesized values for the linear combinations\n",
    "    alpha : float, optional\n",
    "        Significance level for the test. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Test outcome with relevant statistics.\n",
    "        - 'reject': boolean indicating whether to reject the null hypothesis\n",
    "        - 'p_value': p-value for the test\n",
    "        - 'F_stat': F-statistic for the test\n",
    "        - 'f_critical': critical value from the F-distribution\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of observations and predictors\n",
    "    n, k_plus_1 = X.shape\n",
    "\n",
    "    r = C.shape[0]  # Number of linear combinations\n",
    "\n",
    "    # Calculate the least squares estimates\n",
    "    beta_hat, _, sigma2_hat_unbiased = mult_lr_least_squares(X, y)\n",
    "\n",
    "    # Check if c0 is in the confidence region\n",
    "    in_cr = mult_norm_lr_is_in_cr(X=X, y=y, C=C, c0=c0, alpha=alpha)\n",
    "\n",
    "    # H0 is rejected if c0 is not in the confidence region\n",
    "    reject = not in_cr\n",
    "\n",
    "    # Calculate the critical value from the F-distribution\n",
    "    f_critical = stats.f.ppf(1 - alpha, r, n - k_plus_1)\n",
    "\n",
    "    # Calculate F-statistic\n",
    "    C_beta_hat = C @ beta_hat\n",
    "    diff = C_beta_hat - c0\n",
    "    XtX_inv = np.linalg.inv(X.T @ X)\n",
    "    shape_matrix = C @ XtX_inv @ C.T\n",
    "    left_side = diff.T @ np.linalg.inv(shape_matrix) @ diff\n",
    "    F_stat = left_side / (r * sigma2_hat_unbiased)\n",
    "\n",
    "    # Calculate p-value\n",
    "    p_value = 1 - stats.f.cdf(F_stat, r, n - k_plus_1)\n",
    "\n",
    "    return {\n",
    "        'reject': reject,\n",
    "        'p_value': p_value,\n",
    "        'F_stat': F_stat,\n",
    "        'f_critical': f_critical\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ccf4570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_norm_lr_test_comp(X, y, j_indices, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Tests the null hypothesis H0: beta_j = 0 for j in j_indices vs H1: not H0.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        n x (k+1) design matrix where the first column is all ones\n",
    "    y : array_like\n",
    "        n x 1 response vector\n",
    "    j_indices: list of int\n",
    "        Indices of the coefficients to test\n",
    "    alpha : float, optional\n",
    "        Significance level for the test. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Test outcome with relevant statistics.\n",
    "        - 'reject': boolean indicating whether to reject the null hypothesis\n",
    "        - 'p_value': p-value for the test\n",
    "        - 'F_stat': F-statistic for the test\n",
    "        - 'f_critical': critical value from the F-distribution\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of observations and predictors\n",
    "    n, k_plus_1 = X.shape\n",
    "\n",
    "    # Create the contrast matrix C\n",
    "    r = len(j_indices)\n",
    "    C = np.zeros((r, k_plus_1))\n",
    "    for i, j in enumerate(j_indices):\n",
    "        C[i, j] = 1\n",
    "\n",
    "    # Create the hypothesized value vector c0\n",
    "    c0 = np.zeros(r)\n",
    "\n",
    "    # Perform the general test\n",
    "    test_result = mult_norm_lr_test_general(X=X, y=y, C=C, c0=c0, alpha=alpha)\n",
    "    \n",
    "    return test_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0d94879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_norm_lr_test_linear_reg(X, y, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Tests the existence of LR at all, H0: beta_1 = beta_2 = ... = beta_k = 0 vs H1: not H0.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        n x (k+1) design matrix where the first column is all ones\n",
    "    y : array_like\n",
    "        n x 1 response vector\n",
    "    alpha : float, optional\n",
    "        Significance level for the test. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Test outcome with relevant statistics.\n",
    "        - 'reject': boolean indicating whether to reject the null hypothesis\n",
    "        - 'p_value': p-value for the test\n",
    "        - 'F_stat': F-statistic for the test\n",
    "        - 'f_critical': critical value from the F-distribution\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of observations and predictors\n",
    "    n, k_plus_1 = X.shape\n",
    "\n",
    "    j_indices = list(range(1, k_plus_1))  # Exclude the intercept term\n",
    "\n",
    "    # Use the mult_norm_lr_test_comp function to test the null hypothesis\n",
    "    test_result = mult_norm_lr_test_comp(X=X, y=y, j_indices=j_indices, alpha=alpha)\n",
    "\n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b56efb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_norm_lr_pred_ci(X, y, D, alpha=0.05, method=\"best\"):\n",
    "    \"\"\"\n",
    "    Computes simultaneous confidence intervals for d_i^T * beta for rows of D.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like\n",
    "        n x (k+1) design matrix where the first column is all ones\n",
    "    y : array_like\n",
    "        n x 1 response vector\n",
    "    D : array_like\n",
    "        m x (k+1) design matrix for the predictions\n",
    "    alpha : float, optional\n",
    "        Significance level for the confidence intervals. Default is 0.05.\n",
    "    method : str, optional\n",
    "        One of \"Scheffe\", \"Bonferroni\" or \"best\". Default is \"best\".\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        - 'lower': lower bounds for each d_i^T * beta\n",
    "        - 'upper': upper bounds for each d_i^T * beta\n",
    "        - 'method': method used for the confidence intervals\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of observations and predictors\n",
    "    n, k_plus_1 = X.shape\n",
    "\n",
    "    m = D.shape[0]  # Number of predictions\n",
    "\n",
    "    # Calculate the least squares estimates\n",
    "    beta_hat, _, sigma2_hat_unbiased = mult_lr_least_squares(X, y)\n",
    "    S_e  = np.sqrt(sigma2_hat_unbiased)\n",
    "\n",
    "    XtX_inv = np.linalg.inv(X.T @ X)\n",
    "\n",
    "    # Bonferroni critical value\n",
    "    t_crit = stats.t.ppf(1 - alpha / (2 * m), n - k_plus_1)\n",
    "\n",
    "    # Scheffe critical value\n",
    "    scheffe_m = np.sqrt(k_plus_1 * stats.f.ppf(1 - alpha, k_plus_1, n - k_plus_1))\n",
    "\n",
    "    lower_bounds = []\n",
    "    upper_bounds = []\n",
    "\n",
    "    for i in range(m):\n",
    "        d = D[i, :].reshape(-1, 1)  # Reshape to column vector\n",
    "        d_beta_hat = d.T @ beta_hat # 1 x 1 matrix\n",
    "        d_beta_hat = d_beta_hat.item()   # Convert to scalar\n",
    "\n",
    "        se = S_e * np.sqrt(d.T @ XtX_inv @ d)   # 1 x 1 matrix\n",
    "        se = se.item()   # Convert to scalar\n",
    "        \n",
    "        if method == \"Scheffe\":\n",
    "            half_width = scheffe_m * se\n",
    "        elif method == \"Bonferroni\":\n",
    "            half_width = t_crit * se\n",
    "        elif method == \"best\":\n",
    "            half_width = min(scheffe_m, t_crit) * se\n",
    "            method_used = \"Bonferroni\" if half_width == t_crit * se else \"Scheffe\"\n",
    "        else:\n",
    "            raise ValueError(\"Invalid method. Choose 'Scheffe', 'Bonferroni', or 'best'.\")\n",
    "\n",
    "        lower_bounds.append(d_beta_hat - half_width)\n",
    "        upper_bounds.append(d_beta_hat + half_width)\n",
    "    \n",
    "    return {\n",
    "        'lower': np.array(lower_bounds),\n",
    "        'upper': np.array(upper_bounds),\n",
    "        'method': method_used if method == \"best\" else method\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0782ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_anova_examples():\n",
    "    \"\"\"\n",
    "    Run examples of ANOVA functions.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" ANOVA Functions Examples \".center(80, \"=\"))\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Create sample data for one-way ANOVA\n",
    "    np.random.seed(42)\n",
    "    group1 = np.random.normal(loc=10, scale=2, size=15) # Group 1, 15 datapoints from N(10, 2^2)\n",
    "    group2 = np.random.normal(loc=12, scale=2, size=12) # Group 2, 12 datapoints from N(12, 2^2)\n",
    "    group3 = np.random.normal(loc=8, scale=2, size=18)  # Group 3, 18 datapoints from N(8, 2^2)\n",
    "\n",
    "    X_1 = [group1, group2, group3]\n",
    "\n",
    "\n",
    "    # Example 1: ANOVA1 partition TSS\n",
    "    print(\"\\n1. ANOVA1_partition_tss Example:\")\n",
    "    ss_total, ss_w, ss_b = anova1_partition_tss(X_1)\n",
    "    print(f\"Total Sum of Squares (ss_total): {ss_total:.4f}\")\n",
    "    print(f\"Within-group Sum of Squares (ss_w): {ss_w:.4f}\")\n",
    "    print(f\"Between-group Sum of Squares (ss_b): {ss_b:.4f}\")\n",
    "    print(f\"Verification: ss_total = ss_w + ss_b: {ss_total:.4f} = {ss_w + ss_b:.4f}\")\n",
    "\n",
    "\n",
    "    # Example 2: ANOVA1 test equality\n",
    "    print(\"\\n2. ANOVA1_test_equality Example:\")\n",
    "    result = anova1_test_equality(X_1, alpha=0.05)\n",
    "\n",
    "\n",
    "    # Example 3: ANOVA1 is contrast\n",
    "    print(\"\\n3. ANOVA1_is_contrast Example:\")\n",
    "    contrast1 = [1, -1, 0]  # mu_1 - mu_2\n",
    "    contrast2 = [1, 1, -2]  # mu_1 + mu_2 - 2mu_3\n",
    "    non_contrast = [1, 1, 1]    # mu_1 + mu_2 + mu_3\n",
    "\n",
    "    print(f\"Is [1, -1, 0] a contrast? {anova1_is_contrast(c=contrast1)}\")\n",
    "    print(f\"Is [1, 1, -2] a contrast? {anova1_is_contrast(c=contrast2)}\")\n",
    "    print(f\"Is [1, 1, 1] a contrast? {anova1_is_contrast(c=non_contrast)}\")\n",
    "\n",
    "\n",
    "    # Example 4: ANOVA1 is orthogonal\n",
    "    print(\"\\n4. ANOVA1_is_orthogonal Example:\")\n",
    "    group_sizes = [len(group) for group in X_1]\n",
    "    print(f\"Group sizes: {group_sizes}\")\n",
    "    print(f\"Are [1, -1, 0] and [1, 1, -2] orthogonal? {anova1_is_orthogonal(group_sizes=group_sizes, coef1=contrast1, coef2=contrast2)}\")\n",
    "    # print(f\"Are [1, -1, 0] and [1, 1, 1] orthogonal? {anova1_is_orthogonal(group_sizes=group_sizes, coef1=contrast1, coef2=non_contrast)}\")\n",
    "\n",
    "\n",
    "    # Example 5: Bonferroni correction\n",
    "    print(\"\\n5. Bonferroni_correction Example:\")\n",
    "    alpha = 0.05\n",
    "    m = 3\n",
    "    print(f\"Bonferroni correction for FWER={alpha} and m={m}: {bonferroni_correction(alpha=alpha, m=m):.4f}\")\n",
    "\n",
    "\n",
    "    # Example 6: Sidak correction\n",
    "    print(\"\\n6. Sidak_correction Example:\")\n",
    "    print(f\"Sidak correction for FWER={alpha} and m={m}: {sidak_correction(alpha=alpha, m=m):.4f}\")\n",
    "\n",
    "\n",
    "    # Example 7: ANOVA1 CI linear combs\n",
    "    print(\"\\n7. ANOVA1_CI_linear_combs Example:\")\n",
    "    C = np.array([\n",
    "        [1, -1, 0], # mu_1 - mu_2\n",
    "        [1, 0, -1], # mu_1 - mu_3\n",
    "        [0, 1, -1]  # mu_2 - mu_3\n",
    "    ])\n",
    "\n",
    "    print(\"Computing confidence intervals for pairwise differences using different methods:\")\n",
    "\n",
    "    print(\"\\nScheffe's method:\")\n",
    "    intervals_scheffe, _ = anova1_ci_linear_combs(X=X_1, alpha=alpha, C=C, method='Scheffe')\n",
    "    for i, (lower, upper) in enumerate(intervals_scheffe):\n",
    "        print(f\"CI for contrast {i+1}: ({lower:.4f}, {upper:.4f}) --> upper - lower = {upper - lower:.4f}\")\n",
    "\n",
    "    print(\"\\nTukey's method:\")\n",
    "    intervals_tukey, _ = anova1_ci_linear_combs(X=X_1, alpha=alpha, C=C, method=\"Tukey\")\n",
    "    for i, (lower, upper) in enumerate(intervals_tukey):\n",
    "        print(f\"CI for contrast {i+1}: ({lower:.4f}, {upper:.4f}) --> upper - lower = {upper - lower:.4f}\")\n",
    "\n",
    "    print(\"\\nBonferroni's method:\")\n",
    "    intervals_bonferroni, _ = anova1_ci_linear_combs(X=X_1, alpha=alpha, C=C, method=\"Bonferroni\")\n",
    "    for i, (lower, upper) in enumerate(intervals_bonferroni):\n",
    "        print(f\"CI for contrast {i+1}: ({lower:.4f}, {upper:.4f}) --> upper - lower = {upper - lower:.4f}\")\n",
    "\n",
    "    print(\"\\nSidak's method:\")\n",
    "    intervals_sidak, _ = anova1_ci_linear_combs(X=X_1, alpha=alpha, C=C, method=\"Sidak\")\n",
    "    for i, (lower, upper) in enumerate(intervals_sidak):\n",
    "        print(f\"CI for contrast {i+1}: ({lower:.4f}, {upper:.4f}) --> upper - lower = {upper - lower:.4f}\")\n",
    "    \n",
    "    print(\"\\nBest method (should choose Tukey for pairwise differences):\")\n",
    "    intervals_best, _ = anova1_ci_linear_combs(X=X_1, alpha=alpha, C=C, method=\"best\")\n",
    "    for i, (lower, upper) in enumerate(intervals_best):\n",
    "        print(f\"CI for contrast {i+1}: ({lower:.4f}, {upper:.4f}) --> upper - lower = {upper - lower:.4f}\")\n",
    "\n",
    "    \n",
    "    # Example 8: ANOVA1 test linear combs\n",
    "    print(\"\\n8. ANOVA1_test_linear_combs Example:\")\n",
    "    d = np.array([1, 2, -2]) # Testing that all differences are 0\n",
    "    results = anova1_test_linear_combs(X=X_1, alpha=alpha, C=C, d=d, method=\"Sidak\")\n",
    "    print(f\"alpha = {alpha}\")\n",
    "    print(f\"d = {d}\\n\")\n",
    "    for i in range(m):\n",
    "        print(f\"Test for contrast {i+1}:\")\n",
    "        print(f\"p-value: {results['p_values'][i]:.6f}\")\n",
    "        print(f\"Decision: {'Reject H0' if results['reject'][i] else 'Fail to reject H0'}\")\n",
    "        \n",
    "        print(\"\")\n",
    "\n",
    "    \n",
    "    # Create sample data for two-way ANOVA\n",
    "    np.random.seed(42)\n",
    "    I, J, K = 3, 2, 4   # 3 levels of factor A, 2 levels of factor B, and 4 replicates\n",
    "\n",
    "    # Create effects\n",
    "    mu = 10\n",
    "    a_effects = np.array([-1, 0, 1])  # Effects for factor A\n",
    "    b_effects = np.array([-0.5, 0.5])  # Effects for factor B\n",
    "\n",
    "    # Create interaction effects\n",
    "    ab_effects = np.array([\n",
    "        [0.5, -0.5],\n",
    "        [0, 0],\n",
    "        [-0.5, 0.5]\n",
    "    ])\n",
    "\n",
    "    # Generate data\n",
    "    X_2 = np.zeros((I, J, K))\n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            cell_mean = mu + a_effects[i] + b_effects[j] + ab_effects[i, j]\n",
    "            X_2[i, j, :] = np.random.normal(loc=cell_mean, scale=1, size=K) # Normal noise with sd=1\n",
    "\n",
    "\n",
    "    # Example 9: ANOVA2 partition TSS\n",
    "    print(\"\\n9. ANOVA2_partition_tss Example:\")\n",
    "    ss_total, ss_a, ss_b, ss_ab, ss_e = anova2_partition_tss(X_2)\n",
    "    print(f\"Total Sum of Squares (ss_total): {ss_total:.4f}\")\n",
    "    print(f\"Factor A Sum of Squares (ss_a): {ss_a:.4f}\")\n",
    "    print(f\"Factor B Sum of Squares (ss_b): {ss_b:.4f}\")\n",
    "    print(f\"Interaction Sum of Squares (ss_ab): {ss_ab:.4f}\")\n",
    "    print(f\"Error Sum of Squares (ss_e): {ss_e:.4f}\")\n",
    "    print(f\"Verification: ss_total = ss_a + ss_b + ss_ab + ss_e: {ss_total:.4f} = {ss_a + ss_b + ss_ab + ss_e:.4f}\")\n",
    "\n",
    "\n",
    "    # Example 10: ANOVA2 MLE\n",
    "    print(\"\\n10. ANOVA2_mle Example:\")\n",
    "    mu_hat, a_hat, b_hat, delta_hat = anova2_mle(X_2)\n",
    "    print(f\"Estimated grand mean (mu): {mu_hat:.4f}\")\n",
    "    print(f\"Estimated row effects (a): {a_hat}\")\n",
    "    print(f\"Estimated column effects (b): {b_hat}\")\n",
    "    print(f\"Estimated interaction effects (delta):\\n{delta_hat}\")\n",
    "\n",
    "\n",
    "    # Example 11: ANOVA2 test equality\n",
    "    print(\"\\n11. ANOVA2_test_equality Example:\")\n",
    "    \n",
    "    print(\"\\nTesting factor A effects:\")\n",
    "    anova2_test_equality(X_2, alpha=0.05, test_type=\"A\")\n",
    "\n",
    "    print(\"\\nTesting factor B effects:\")\n",
    "    anova2_test_equality(X_2, alpha=0.05, test_type=\"B\")\n",
    "\n",
    "    print(\"\\nTesting interaction effects:\")\n",
    "    anova2_test_equality(X_2, alpha=0.05, test_type=\"AB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8c4e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression_examples():\n",
    "    \"\"\" Run examples of regression functions. \"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" Linear Regression Functions Examples \".center(80, \"=\"))\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Create sample data for multiple linear regression\n",
    "    np.random.seed(42)\n",
    "    n = 100\n",
    "    k_plus_1 = 4    # 3 predictors + intercept\n",
    "\n",
    "    # True coefficients\n",
    "    beta_true = np.array([2, 1.5, -0.5, 0.8])\n",
    "\n",
    "    # Design matrix (X) with intercept\n",
    "    X = np.ones((n, k_plus_1))\n",
    "    X[:, 1] = np.random.uniform(-2, 2, n)  # Predictor 1\n",
    "    X[:, 2] = np.random.uniform(-3, 3, n)  # Predictor 2\n",
    "    X[:, 3] = np.random.uniform(-1, 1, n)  # Predictor 3\n",
    "\n",
    "    # Response variable (y) with noise\n",
    "    sigma = 1.0 # Standard deviation of error\n",
    "    error = np.random.normal(0, sigma, n)\n",
    "    y = X @ beta_true + error\n",
    "\n",
    "    # Example 1: Mult_LR_least_squares\n",
    "    print(\"\\n1. Mult_LR_Least_squares Example:\")\n",
    "    beta_hat, sigma2_hat, sigma2_hat_unbiased = mult_lr_least_squares(X, y)\n",
    "    print(f\"True beta: {beta_true}\")\n",
    "    print(f\"Estimated beta: {beta_hat}\")\n",
    "    print(f\"\\nTrue sigma^2: {sigma**2:.4f}\")\n",
    "    print(f\"MLE of sigma^2: {sigma2_hat:.4f}\")\n",
    "    print(f\"Unbiased estimate of sigma^2: {sigma2_hat_unbiased:.4f}\")\n",
    "\n",
    "    # Example 2: Mult_LR_partition_tss\n",
    "    print(\"\\n2. Mult_LR_partition_TSS Example:\")\n",
    "    ss_total, ss_reg, ss_res = mult_lr_partition_tss(X, y)\n",
    "    print(f\"Total Sum of Squares (ss_total): {ss_total:.4f}\")\n",
    "    print(f\"Regression Sum of Squares (ss_reg): {ss_reg:.4f}\")\n",
    "    print(f\"Residual Sum of Squares (ss_res): {ss_res:.4f}\")\n",
    "    print(f\"Verification: ss_total = ss_reg + ss_res: {ss_total:.4f} = {ss_reg + ss_res:.4f}\")\n",
    "    \n",
    "    # Example 3: Mult_norm_LR_simul_CI\n",
    "    print(\"\\n3. Mult_norm_LR_simul_CI Example:\")\n",
    "    print(f\"True beta: {beta_true}\")\n",
    "    alpha = 0.05\n",
    "    ci, method = mult_norm_lr_simul_ci(X, y, alpha=alpha)\n",
    "    print(f\"Simultaneous confidence intervals using method: {method}\")\n",
    "    for i, (lower, upper) in enumerate(ci):\n",
    "        # print(f\"CI for beta_{i}: ({lower:.4f}, {upper:.4f}) --> upper - lower = {upper - lower:.4f}\")\n",
    "        print(f\"{100*(1 - alpha)}% CI for beta_{i}: ({lower:.4f}, {upper:.4f})\")\n",
    "\n",
    "    # Example 4: Mult_norm_LR_CR\n",
    "    print(\"\\n4. Mult_norm_LR_CR Example:\")\n",
    "    # Test for the first two coefficients\n",
    "    C = np.array([\n",
    "        [1, 0, 0, 0],  # beta_0\n",
    "        [0, 1, 0, 0]  # beta_1\n",
    "    ])\n",
    "    alpha = 0.05\n",
    "    cr = mult_norm_lr_cr(X, y, C, alpha=alpha)\n",
    "    print(f\"Center of the confidence region: {cr['center']}\")\n",
    "    print(f\"Shape matrix of the confidence region:\\n{cr['shape_matrix']}\")\n",
    "    print(f\"Radius squared of the confidence region: {cr['radius_squared']:.4f}\")\n",
    "\n",
    "    # Example 5: Mult_norm_LR_is_in_CR\n",
    "    print(\"\\n5. Mult_norm_LR_is_in_CR Example:\")\n",
    "    # Check if the true coefficients are inside the confidence region\n",
    "    c0 = np.array([beta_true[0], beta_true[1]])\n",
    "    is_in_cr = mult_norm_lr_is_in_cr(X, y, C, c0, alpha=alpha)\n",
    "    print(f\"Is the true coefficient vector {c0} inside the confidence region? {'Yes' if is_in_cr else 'No'}\")\n",
    "\n",
    "    # Check if a different vector is inside the confidence region\n",
    "    c0 = np.array([2, 1])\n",
    "    is_in_cr = mult_norm_lr_is_in_cr(X, y, C, c0, alpha=alpha)\n",
    "    print(f\"Is the vector {c0} inside the confidence region? {'Yes' if is_in_cr else 'No'}\")\n",
    "\n",
    "    # Example 6: Mult_norm_LR_test_general\n",
    "    print(\"\\n6. Mult_norm_LR_test_general Example:\")\n",
    "    # Test the null hypothesis H0: C*beta = c0\n",
    "    # True coefficients\n",
    "    c0 = np.array([beta_true[0], beta_true[1]])\n",
    "    test_result = mult_norm_lr_test_general(X, y, C, c0, alpha=alpha)\n",
    "    print(f\"Test result for H0: C*beta = c0 where c0 = {c0}\")\n",
    "    print(f\"p-value: {test_result['p_value']:.4f} > {alpha}\")\n",
    "    print(f\"F-statistic: {test_result['F_stat']:.4f}\")\n",
    "    print(f\"Critical value: {test_result['f_critical']:.4f}\")\n",
    "    print(f\"Decision: {'Reject H0' if test_result['reject'] else 'Fail to reject H0'}\")\n",
    "    print(\"\")\n",
    "    # Test false hypothesis\n",
    "    c0 = np.array([2, 1])\n",
    "    test_result = mult_norm_lr_test_general(X, y, C, c0, alpha=alpha)\n",
    "    print(f\"Test result for H0: C*beta = c0 where c0 = {c0}\")\n",
    "    print(f\"p-value: {test_result['p_value']:.4f} < {alpha}\")\n",
    "    print(f\"F-statistic: {test_result['F_stat']:.4f}\")\n",
    "    print(f\"Critical value: {test_result['f_critical']:.4f}\")\n",
    "    print(f\"Decision: {'Reject H0' if test_result['reject'] else 'Fail to reject H0'}\")\n",
    "\n",
    "    # Example 7: Mult_norm_LR_test_comp\n",
    "    print(\"\\n7. Mult_norm_LR_test_comp Example:\")\n",
    "    # Test if beta_2 = 0 and beta_3 = 0\n",
    "    j_indices = [2, 3]\n",
    "    test_result = mult_norm_lr_test_comp(X, y, j_indices, alpha=alpha)\n",
    "    print(f\"Test result for H0: beta_j = 0 for j in {j_indices}\")\n",
    "    print(f\"p-value: {test_result['p_value']:.4f} < {alpha}\")\n",
    "    print(f\"F-statistic: {test_result['F_stat']:.4f}\")\n",
    "    print(f\"Critical value: {test_result['f_critical']:.4f}\")\n",
    "    print(f\"Decision: {'Reject H0' if test_result['reject'] else 'Fail to reject H0'}\")\n",
    "    \n",
    "    # Example 8: Mult_norm_LR_test_linear_reg\n",
    "    print(\"\\n8. Mult_norm_LR_test_linear_reg Example:\")\n",
    "    # Test if all coefficients (except intercept) are equal to 0\n",
    "    test_result = mult_norm_lr_test_linear_reg(X, y, alpha=alpha)\n",
    "    print(f\"Test result for H0: beta_1 = beta_2 = ... = beta_k = 0\")\n",
    "    print(f\"p-value: {test_result['p_value']:.4f} < {alpha}\")\n",
    "    print(f\"F-statistic: {test_result['F_stat']:.4f}\")\n",
    "    print(f\"Critical value: {test_result['f_critical']:.4f}\")\n",
    "    print(f\"Decision: {'Reject H0' if test_result['reject'] else 'Fail to reject H0'}\")\n",
    "\n",
    "    # Example 9: Mult_norm_LR_pred_CI\n",
    "    print(\"\\n9. Mult_norm_LR_pred_CI Example:\")\n",
    "    # Create a new design matrix for predictions\n",
    "    D = np.array([\n",
    "        [1, -1, -1, -1],  # Prediction 1\n",
    "        [1, 0, 0, 0],   # Prediction 2\n",
    "        [1, 1, 1, 1]    # Prediction 3\n",
    "    ])\n",
    "    \n",
    "    # True predicted values\n",
    "    true_preds = D @ beta_true\n",
    "\n",
    "    results = mult_norm_lr_pred_ci(X, y, D, alpha=alpha, method=\"best\")\n",
    "    print(\"Method used:\", results['method'])    \n",
    "    for i in range(D.shape[0]):\n",
    "        \n",
    "        lower = results['lower'][i]\n",
    "        upper = results['upper'][i]\n",
    "        \n",
    "        print(f\"Prediction {i+1}: True value = {true_preds[i]:.4f}, CI = ({lower:.4f}, {upper:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6cd3a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"\\n\" + \"*\" * 80)\n",
    "    print(\" ANOVA and Linear Regression Toolbox Demo \".center(80, \"*\"))\n",
    "    print(\"*\"*80)\n",
    "\n",
    "    # Run ANOVA examples\n",
    "    run_anova_examples()\n",
    "\n",
    "    # Run regression examples\n",
    "    run_regression_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "926431f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************\n",
      "******************* ANOVA and Linear Regression Toolbox Demo *******************\n",
      "********************************************************************************\n",
      "\n",
      "================================================================================\n",
      "=========================== ANOVA Functions Examples ===========================\n",
      "================================================================================\n",
      "\n",
      "1. ANOVA1_partition_tss Example:\n",
      "Total Sum of Squares (ss_total): 253.2957\n",
      "Within-group Sum of Squares (ss_w): 146.7128\n",
      "Between-group Sum of Squares (ss_b): 106.5830\n",
      "Verification: ss_total = ss_w + ss_b: 253.2957 = 253.2957\n",
      "\n",
      "2. ANOVA1_test_equality Example:\n",
      "\n",
      "ANOVA Table\n",
      "--------------------------------------------------------------------------------\n",
      "Source          df         SS              MS              F              \n",
      "--------------------------------------------------------------------------------\n",
      "Between         2          106.5830        53.2915         15.2559        \n",
      "Within          42         146.7128        3.4932         \n",
      "Total           44         253.2957       \n",
      "--------------------------------------------------------------------------------\n",
      "Critical value (f_0.05_2_42): 3.2199\n",
      "p-value: 0.00001046\n",
      "Decision (alpha=0.05): Reject H0\n",
      "Interpretation: There is signifant evidence to suggest that at least one group mean is different.\n",
      "\n",
      "3. ANOVA1_is_contrast Example:\n",
      "Is [1, -1, 0] a contrast? True\n",
      "Is [1, 1, -2] a contrast? True\n",
      "Is [1, 1, 1] a contrast? False\n",
      "\n",
      "4. ANOVA1_is_orthogonal Example:\n",
      "Group sizes: [15, 12, 18]\n",
      "Are [1, -1, 0] and [1, 1, -2] orthogonal? False\n",
      "\n",
      "5. Bonferroni_correction Example:\n",
      "Bonferroni correction for FWER=0.05 and m=3: 0.0167\n",
      "\n",
      "6. Sidak_correction Example:\n",
      "Sidak correction for FWER=0.05 and m=3: 0.0170\n",
      "\n",
      "7. ANOVA1_CI_linear_combs Example:\n",
      "Computing confidence intervals for pairwise differences using different methods:\n",
      "\n",
      "Scheffe's method:\n",
      "Using method: Scheffe\n",
      "CI for contrast 1: (-2.9357, 0.7381) --> upper - lower = 3.6739\n",
      "CI for contrast 2: (0.8740, 4.1903) --> upper - lower = 3.3163\n",
      "CI for contrast 3: (1.8634, 5.3986) --> upper - lower = 3.5352\n",
      "\n",
      "Tukey's method:\n",
      "Using method: Tukey\n",
      "CI for contrast 1: (-2.8574, 0.6598) --> upper - lower = 3.5172\n",
      "CI for contrast 2: (0.9447, 4.1196) --> upper - lower = 3.1749\n",
      "CI for contrast 3: (1.9387, 5.3232) --> upper - lower = 3.3845\n",
      "\n",
      "Bonferroni's method:\n",
      "Using method: Bonferroni\n",
      "CI for contrast 1: (-2.9039, 0.7063) --> upper - lower = 3.6101\n",
      "CI for contrast 2: (0.9028, 4.1615) --> upper - lower = 3.2588\n",
      "CI for contrast 3: (1.8940, 5.3679) --> upper - lower = 3.4739\n",
      "\n",
      "Sidak's method:\n",
      "Using method: Sidak\n",
      "CI for contrast 1: (-2.8988, 0.7012) --> upper - lower = 3.6001\n",
      "CI for contrast 2: (0.9073, 4.1570) --> upper - lower = 3.2497\n",
      "CI for contrast 3: (1.8989, 5.3630) --> upper - lower = 3.4642\n",
      "\n",
      "Best method (should choose Tukey for pairwise differences):\n",
      "Using method: Tukey\n",
      "CI for contrast 1: (-2.8574, 0.6598) --> upper - lower = 3.5172\n",
      "CI for contrast 2: (0.9447, 4.1196) --> upper - lower = 3.1749\n",
      "CI for contrast 3: (1.9387, 5.3232) --> upper - lower = 3.3845\n",
      "\n",
      "8. ANOVA1_test_linear_combs Example:\n",
      "Using method: Sidak\n",
      "alpha = 0.05\n",
      "d = [ 1  2 -2]\n",
      "\n",
      "Test for contrast 1:\n",
      "p-value: 0.001978\n",
      "Decision: Reject H0\n",
      "\n",
      "Test for contrast 2:\n",
      "p-value: 0.166041\n",
      "Decision: Fail to reject H0\n",
      "\n",
      "Test for contrast 3:\n",
      "p-value: 0.000000\n",
      "Decision: Reject H0\n",
      "\n",
      "\n",
      "9. ANOVA2_partition_tss Example:\n",
      "Total Sum of Squares (ss_total): 35.4218\n",
      "Factor A Sum of Squares (ss_a): 6.9446\n",
      "Factor B Sum of Squares (ss_b): 5.1785\n",
      "Interaction Sum of Squares (ss_ab): 9.8306\n",
      "Error Sum of Squares (ss_e): 13.4681\n",
      "Verification: ss_total = ss_a + ss_b + ss_ab + ss_e: 35.4218 = 35.4218\n",
      "\n",
      "10. ANOVA2_mle Example:\n",
      "Estimated grand mean (mu): 9.8524\n",
      "Estimated row effects (a): [-0.30142104 -0.45418486  0.7556059 ]\n",
      "Estimated column effects (b): [-0.46451214  0.46451214]\n",
      "Estimated interaction effects (delta):\n",
      "[[ 0.54586352 -0.54586352]\n",
      " [ 0.35231984 -0.35231984]\n",
      " [-0.89818336  0.89818336]]\n",
      "\n",
      "11. ANOVA2_test_equality Example:\n",
      "\n",
      "Testing factor A effects:\n",
      "\n",
      "Two-Way ANOVA Table:\n",
      "--------------------------------------------------------------------------------\n",
      "Source          df         SS              MS              F              \n",
      "--------------------------------------------------------------------------------\n",
      "Factor A        2          6.9446          3.4723          4.6407         \n",
      "Error           18         13.4681         0.7482         \n",
      "Total           23         35.4218        \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Testing H0: a_1 = a_2 = ... = a_I\n",
      "Decision (alpha=0.05): Reject H0\n",
      "p-value: 0.0237\n",
      "Critical value (f): 3.5546\n",
      "\n",
      "Testing factor B effects:\n",
      "\n",
      "Two-Way ANOVA Table:\n",
      "--------------------------------------------------------------------------------\n",
      "Source          df         SS              MS              F              \n",
      "--------------------------------------------------------------------------------\n",
      "Factor B        1          5.1785          5.1785          6.9211         \n",
      "Error           18         13.4681         0.7482         \n",
      "Total           23         35.4218        \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Testing H0: b_1 = b_2 = ... = b_J\n",
      "Decision (alpha=0.05): Reject H0\n",
      "p-value: 0.0170\n",
      "Critical value (f): 4.4139\n",
      "\n",
      "Testing interaction effects:\n",
      "\n",
      "Two-Way ANOVA Table:\n",
      "--------------------------------------------------------------------------------\n",
      "Source          df         SS              MS              F              \n",
      "--------------------------------------------------------------------------------\n",
      "Interaction     2          9.8306          4.9153          6.5693         \n",
      "Error           18         13.4681         0.7482         \n",
      "Total           23         35.4218        \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Testing H0: all delta_ij = 0\n",
      "Decision (alpha=0.05): Reject H0\n",
      "p-value: 0.0072\n",
      "Critical value (f): 3.5546\n",
      "\n",
      "================================================================================\n",
      "===================== Linear Regression Functions Examples =====================\n",
      "================================================================================\n",
      "\n",
      "1. Mult_LR_Least_squares Example:\n",
      "True beta: [ 2.   1.5 -0.5  0.8]\n",
      "Estimated beta: [ 2.0768857   1.60398232 -0.46524171  0.96467409]\n",
      "\n",
      "True sigma^2: 1.0000\n",
      "MLE of sigma^2: 0.9283\n",
      "Unbiased estimate of sigma^2: 0.9670\n",
      "\n",
      "2. Mult_LR_partition_TSS Example:\n",
      "Total Sum of Squares (ss_total): 567.3840\n",
      "Regression Sum of Squares (ss_reg): 474.5550\n",
      "Residual Sum of Squares (ss_res): 92.8291\n",
      "Verification: ss_total = ss_reg + ss_res: 567.3840 = 567.3840\n",
      "\n",
      "3. Mult_norm_LR_simul_CI Example:\n",
      "True beta: [ 2.   1.5 -0.5  0.8]\n",
      "Simultaneous confidence intervals using method: Bonferroni\n",
      "95.0% CI for beta_0: (1.8249, 2.3289)\n",
      "95.0% CI for beta_1: (1.3922, 1.8157)\n",
      "95.0% CI for beta_2: (-0.6100, -0.3205)\n",
      "95.0% CI for beta_3: (0.5309, 1.3984)\n",
      "\n",
      "4. Mult_norm_LR_CR Example:\n",
      "Center of the confidence region: [2.0768857  1.60398232]\n",
      "Shape matrix of the confidence region:\n",
      "[[0.01013351 0.00083373]\n",
      " [0.00083373 0.00715506]]\n",
      "Radius squared of the confidence region: 5.9782\n",
      "\n",
      "5. Mult_norm_LR_is_in_CR Example:\n",
      "Is the true coefficient vector [2.  1.5] inside the confidence region? Yes\n",
      "Is the vector [2 1] inside the confidence region? No\n",
      "\n",
      "6. Mult_norm_LR_test_general Example:\n",
      "Test result for H0: C*beta = c0 where c0 = [2.  1.5]\n",
      "p-value: 0.3726 > 0.05\n",
      "F-statistic: 0.9975\n",
      "Critical value: 3.0912\n",
      "Decision: Fail to reject H0\n",
      "\n",
      "Test result for H0: C*beta = c0 where c0 = [2 1]\n",
      "p-value: 0.0000 < 0.05\n",
      "F-statistic: 26.3650\n",
      "Critical value: 3.0912\n",
      "Decision: Reject H0\n",
      "\n",
      "7. Mult_norm_LR_test_comp Example:\n",
      "Test result for H0: beta_j = 0 for j in [2, 3]\n",
      "p-value: 0.0000 < 0.05\n",
      "F-statistic: 57.6150\n",
      "Critical value: 3.0912\n",
      "Decision: Reject H0\n",
      "\n",
      "8. Mult_norm_LR_test_linear_reg Example:\n",
      "Test result for H0: beta_1 = beta_2 = ... = beta_k = 0\n",
      "p-value: 0.0000 < 0.05\n",
      "F-statistic: 163.5884\n",
      "Critical value: 2.6994\n",
      "Decision: Reject H0\n",
      "\n",
      "9. Mult_norm_LR_pred_CI Example:\n",
      "Method used: Bonferroni\n",
      "Prediction 1: True value = 0.2000, CI = (-0.5910, 0.5380)\n",
      "Prediction 2: True value = 2.0000, CI = (1.8357, 2.3181)\n",
      "Prediction 3: True value = 3.8000, CI = (3.6181, 4.7425)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats_toolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
